{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71ed017-e1b0-4299-88b3-f0eb05adc4df",
   "metadata": {},
   "source": [
    "# The Price is Right\n",
    "\n",
    "The final step is to build a User Interface\n",
    "\n",
    "We will use more advanced aspects of Gradio - building piece by piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614c6202-4575-448d-98ee-78b735775d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from deal_agent_framework import DealAgentFramework\n",
    "from agents.deals import Opportunity, Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0534e714-5a9c-45c6-998c-3472ac0bb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(title=\"The Price is Right\", fill_width=True) as ui:\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:24px\">The Price is Right - Deal Hunting Agentic AI</div>')\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:14px\">Autonomous agent framework that finds online deals, collaborating with a proprietary fine-tuned LLM deployed on Modal, and a RAG pipeline with a frontier model and Chroma.</div>')\n",
    "        \n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c12c10-750c-4da3-8df5-f2bc3393f9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 323, in select\n",
      "    r, w, _ = self._select(self._readers, self._writers, [], timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 314, in _select\n",
      "    r, w, x = select.select(r, w, w, timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 10055] An operation on a socket could not be performed because the system lacked sufficient buffer space or because a queue was full\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 699, in lifespan\n",
      "    await receive()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\lifespan\\on.py\", line 137, in receive\n",
      "    return await self.receive_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\queues.py\", line 158, in get\n",
      "    await getter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 323, in select\n",
      "    r, w, _ = self._select(self._readers, self._writers, [], timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 314, in _select\n",
      "    r, w, x = select.select(r, w, w, timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 10055] An operation on a socket could not be performed because the system lacked sufficient buffer space or because a queue was full\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 821, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 74, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 263, in __call__\n",
      "    async with anyio.create_task_group() as task_group:\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 776, in __aexit__\n",
      "    raise exc_val\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 270, in __call__\n",
      "    await wrap(partial(self.listen_for_disconnect, receive))\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 266, in wrap\n",
      "    await func()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 234, in listen_for_disconnect\n",
      "    message = await receive()\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 563, in receive\n",
      "    await self.message_event.wait()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in thread Thread-10 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 323, in select\n",
      "    r, w, _ = self._select(self._readers, self._writers, [], timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\selectors.py\", line 314, in _select\n",
      "    r, w, x = select.select(r, w, w, timeout)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 10055] An operation on a socket could not be performed because the system lacked sufficient buffer space or because a queue was full\n"
     ]
    }
   ],
   "source": [
    "# Updated to change from height to max_height due to change in Gradio v5\n",
    "# With much thanks to student Ed B. for raising this\n",
    "\n",
    "with gr.Blocks(title=\"The Price is Right\", fill_width=True) as ui:\n",
    "\n",
    "    initial_deal = Deal(product_description=\"Example description\", price=100.0, url=\"https://cnn.com\")\n",
    "    initial_opportunity = Opportunity(deal=initial_deal, estimate=200.0, discount=100.0)\n",
    "    opportunities = gr.State([initial_opportunity])\n",
    "\n",
    "    def get_table(opps):\n",
    "        return [[opp.deal.product_description, opp.deal.price, opp.estimate, opp.discount, opp.deal.url] for opp in opps]\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:24px\">\"The Price is Right\" - Deal Hunting Agentic AI</div>')\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:14px\">Deals surfaced so far:</div>')\n",
    "    with gr.Row():\n",
    "        opportunities_dataframe = gr.Dataframe(\n",
    "            headers=[\"Description\", \"Price\", \"Estimate\", \"Discount\", \"URL\"],\n",
    "            wrap=True,\n",
    "            column_widths=[4, 1, 1, 1, 2],\n",
    "            row_count=10,\n",
    "            col_count=5,\n",
    "            max_height=400,\n",
    "        )\n",
    "\n",
    "    ui.load(get_table, inputs=[opportunities], outputs=[opportunities_dataframe])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87106328-a17a-447e-90b9-c547613468da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 16:00:55 +0100] [Agents] [INFO] Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] Collection products is not created.\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Initializing Agent Framework\u001b[0m\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[40m\u001b[32m[Planning Agent] Planning Agent is initializing\u001b[0m\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[40m\u001b[33m[Ensemble Agent] Initializing Ensemble Agent\u001b[0m\n",
      "[2025-05-08 16:00:56 +0100] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\asyncio\\events.py:84: DeprecationError: 2025-01-27: `modal.Cls.lookup` is deprecated and will be removed in a future release. It can be replaced with `modal.Cls.from_name`.\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more information.\n",
      "  self._context.run(self._callback, *self._args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 16:00:57 +0100] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "[2025-05-08 16:00:57 +0100] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "[2025-05-08 16:00:57 +0100] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is setting up with OpenAI\u001b[0m\n",
      "[2025-05-08 16:00:58 +0100] [Agents] [INFO] Use pytorch device_name: cuda\n",
      "[2025-05-08 16:00:58 +0100] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-05-08 16:01:04 +0100] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "[2025-05-08 16:01:04 +0100] [Agents] [INFO] \u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is initializing\u001b[0m\n",
      "[2025-05-08 16:01:04 +0100] [Agents] [INFO] Use pytorch device_name: cuda\n",
      "[2025-05-08 16:01:04 +0100] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\OMKAR\\anaconda3\\envs\\llms\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 16:02:13 +0100] [Agents] [INFO] \u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is ready\u001b[0m\n",
      "[2025-05-08 16:02:26 +0100] [Agents] [INFO] \u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent is ready\u001b[0m\n",
      "[2025-05-08 16:02:26 +0100] [Agents] [INFO] \u001b[40m\u001b[37m[Messaging Agent] Messaging Agent is initializing\u001b[0m\n",
      "[2025-05-08 16:02:26 +0100] [Agents] [INFO] \u001b[40m\u001b[37m[Messaging Agent] Messaging Agent has initialized Pushover\u001b[0m\n",
      "[2025-05-08 16:02:26 +0100] [Agents] [INFO] \u001b[40m\u001b[32m[Planning Agent] Planning Agent is ready\u001b[0m\n",
      "[2025-05-08 16:02:26 +0100] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Agent Framework is ready\u001b[0m\n",
      "[2025-05-08 16:02:34 +0100] [Agents] [INFO] HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "[2025-05-08 16:02:35 +0100] [Agents] [INFO] HTTP Request: GET http://127.0.0.1:7862/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "[2025-05-08 16:02:35 +0100] [Agents] [INFO] HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 16:02:48 +0100] [Agents] [INFO] \u001b[40m\u001b[37m[Messaging Agent] Messaging Agent is sending a push notification\u001b[0m\n",
      "[2025-05-08 16:02:49 +0100] [Agents] [INFO] \u001b[40m\u001b[37m[Messaging Agent] Messaging Agent has completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_framework = DealAgentFramework()\n",
    "agent_framework.init_agents_as_needed()\n",
    "\n",
    "with gr.Blocks(title=\"The Price is Right\", fill_width=True) as ui:\n",
    "\n",
    "    initial_deal = Deal(product_description=\"Example description\", price=100.0, url=\"https://cnn.com\")\n",
    "    initial_opportunity = Opportunity(deal=initial_deal, estimate=200.0, discount=100.0)\n",
    "    opportunities = gr.State([initial_opportunity])\n",
    "\n",
    "    def get_table(opps):\n",
    "        return [[opp.deal.product_description, opp.deal.price, opp.estimate, opp.discount, opp.deal.url] for opp in opps]\n",
    "\n",
    "    def do_select(opportunities, selected_index: gr.SelectData):\n",
    "        row = selected_index.index[0]\n",
    "        opportunity = opportunities[row]\n",
    "        agent_framework.planner.messenger.alert(opportunity)\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:24px\">\"The Price is Right\" - Deal Hunting Agentic AI</div>')\n",
    "    with gr.Row():\n",
    "        gr.Markdown('<div style=\"text-align: center;font-size:14px\">Deals surfaced so far:</div>')\n",
    "    with gr.Row():\n",
    "        opportunities_dataframe = gr.Dataframe(\n",
    "            headers=[\"Description\", \"Price\", \"Estimate\", \"Discount\", \"URL\"],\n",
    "            wrap=True,\n",
    "            column_widths=[4, 1, 1, 1, 2],\n",
    "            row_count=10,\n",
    "            col_count=5,\n",
    "            max_height=400,\n",
    "        )\n",
    "\n",
    "    ui.load(get_table, inputs=[opportunities], outputs=[opportunities_dataframe])\n",
    "    opportunities_dataframe.select(do_select, inputs=[opportunities], outputs=[])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfed67b-ebcb-4e17-ad15-a7151f940119",
   "metadata": {},
   "source": [
    "# Time for the code\n",
    "\n",
    "And now we'll move to the price_is_right.py code, followed by price_is_right_final.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783af8a-08a8-4e59-886a-7ca32f16bcf5",
   "metadata": {},
   "source": [
    "# Running the final product\n",
    "\n",
    "## Just hit shift + enter in the next cell, and let the deals flow in!!\n",
    "\n",
    "Note that the Frontier Agent will use DeepSeek if there's a DEEPSEEK_API_KEY in your .env file, otherwise gpt-4o-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48506465-1c7a-433f-a665-b277a8b4665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python price_is_right_final.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d1243-fbec-4807-988b-8f70c8c9b806",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">But wait!! There's more..</h2>\n",
    "            <span style=\"color:#900;\">If you're not fed up of product prices yet 😂 I've built this out some more!<br/>\n",
    "            If you look in my repo <a href=\"https://github.com/ed-donner/tech2ai\">tech2ai</a>, in segment3/lab1 is a neural network implementation of the pricer in pure PyTorch. It does pretty well..<br/>\n",
    "            And in segment4/agents is this same Agent project taken further. There's a new version of the PlanningAgent called AutonomousPlanningAgent that uses multiple Tools, and a MessagingAgent that uses claude-3.7 to write texts.<br/>\n",
    "            You could experiment with similar ideas to build out this framework.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a2044-566f-4866-be4d-7542b7dfdf3f",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">CONGRATULATIONS AND THANK YOU!!!</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                It's so fabulous that you've made it to the very end! My heartiest congratulations. Please stay in touch! I'm <a href=\"https://www.linkedin.com/in/eddonner/\">here on LinkedIn</a> if we're not already connected and I'm on X at <a href=\"https://x.com/edwarddonner\">@edwarddonner</a>. And my editor would be cross with me if I didn't mention one more time: it makes a HUGE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. <br/><br/>Massive thanks again for putting up with me for 8 weeks and getting all the way to the final cell! I'm excited to hear all about your career as an LLM Engineer. If you post on LinkedIn about completing the course and tag me, then I'll weigh in to amplify your achievement. <br/><b>You could not have picked a better time to be in this field.</b>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd0a27-7d46-4c9e-bbe4-a61c9c899c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
